{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns #for representation of relationship between variables.\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('ANZ synthesised transaction dataset.xlsx', header=0)\n",
    "df.head() #checking first five entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() #gives the info about the whole dataframe\n",
    "#the non null count is showing how many values are filled. One way for a quick guess to know the null values is also subtract the total count which in this #case is 12043 by the number of count given here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail() #checking last 5 entries"
   ]
  },
  {
   "source": [
    "DATA CLEANING:\n",
    "\n",
    "Analysing and Dropping for columns that have a higher percentage of missing values Or are not relevant to the insights that are asked by the client  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Removing columns with 40% null values as they will not not project good insights instead cause distortions and replacing the null values with mode value for 40% of missing data can provide misleading results."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['status', 'card_present_flag', 'account', 'currency', 'long_lat',\n",
       "       'txn_description', 'merchant_id', 'first_name', 'balance', 'date',\n",
       "       'gender', 'age', 'merchant_suburb', 'merchant_state', 'extraction',\n",
       "       'amount', 'transaction_id', 'country', 'customer_id',\n",
       "       'merchant_long_lat', 'movement'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "source": [
    "df_majority = df.dropna(axis=1, thresh=int(0.4*len(df)))\n",
    "df_majority.columns"
   ]
  },
  {
   "source": [
    "Further analysing the dataset  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping columns which do not assist in providing insights\n",
    "df_filtered = df_majority.drop(['status', 'currency', 'country'], axis=1)"
   ]
  },
  {
   "source": [
    "De\n",
    "tecting outliers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpay_biller_code_df = df['bpay_biller_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpay_biller_code_df.isnull().sum()"
   ]
  },
  {
   "source": [
    "Checking the percentage of null values in each column. So columns to check are card_present_flag, bpay_biller_code, merchant_id, merchant_code,  merchant_suburb, merchant_state"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "card_present_flag_df = df['card_present_flag']\n",
    "card_present_flag_df.unique() #checking for unique values\n",
    "scipy.stats.mode(card_present_flag_df)#checking the mode incase we decide to replace missing values with most frequent values\n",
    "percentage_card_present_flag = (card_present_flag_df.isnull().sum()/(len(df)*1.0)*100) #checking the percentage of missing data to make a decision on whether to drop the column or replace the null values\n",
    "\n",
    "percentage_card_present_flag \n",
    "\n",
    "#Since 35% of data is missing, removing the rows with missing values or replacing the nan values with the value of the mode will lead to distorted results. \n",
    "#Also, The data provided seems to be incorrect as the transactions from 3 months prior also show that their status is authorized and not posted which in real case, cases from 3 months prior should all be posted.\n",
    "\n",
    "#Terms Description:\n",
    "\n",
    "# Authorized: A pending transaction is an approved debit or credit transaction that has not been fully processed yet (i.e. has not been posted)\n",
    "\n",
    "# Posted: A posted transaction is a debit or credit that has been fully processed. Once a transaction is posted the account balance on the account is also updated.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpay_biller_code_df = xl['bpay_biller_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpay_biller_code_df.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_bpay_biller_code_df = (bpay_biller_code_df.isnull().sum()/(len(df)*1.0)*100) \n",
    "percentage_bpay_biller_code_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merchant_id_df = df['merchant_id']\n",
    "merchant_id_df.isnull().sum()\n",
    "#scipy.stats.mode(merchant_id_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(4326/12043) #this means around 35% of null values we have "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merchant_id_df.value_counts()#since vast majority of merchant id's are differnt, it will be difficult to approximate the null values to be inserted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merchant_code_df = xl['merchant_code']\n",
    "percentage_merchant_code = (merchant_code_df.isnull().sum()/(len(xl)*1.0)*100)\n",
    "percentage_merchant_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merchant_suburb_df = xl['merchant_suburb']\n",
    "percentage_merchant_suburb = (merchant_suburb_df.isnull().sum()/(len(xl)*1.0)*100)\n",
    "percentage_merchant_suburb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl.nunique() #checking unique values that are not reiterated or redundant. Gives type of data(eg: gender has m and f repeating, so the value is 2) repeated. "
   ]
  },
  {
   "source": [
    "Dealing with missing values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlDropNa = xl.dropna(axis=1, thresh=int(0.9*len(xl)))\n",
    "xlDropNa.isnull().sum()\n",
    "xlDropNa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlDropNa2 = xlDropNa.dropna(axis=0, thresh=int(0.4*len(xlDropNa.columns)))\n",
    "xlDropNa2.isnull().sum()\n",
    "xlDropNa2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropData = xl.drop(['country', 'currency', 'card_present_flag', 'merchant_code', 'bpay_biller_code', 'transaction_id', 'merchant_suburb', 'merchant_id', 'merchant_state', 'merchant_long_lat'], axis =1)  #dropping the columns that are not relevant to our discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropData.isnull().sum() #checking for null values in the dropData dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS JUST A TEST BLOCK FOR LEARNING VISUALISATION\n",
    "# testAmount = np.median(dropData['amount'])\n",
    "# sns.distplot(testAmount, kde=False, bins=10, hist_kws=dict(edgecolor=\"k\", linewidth=2))\n",
    "# plt.xlabel('gu')\n",
    "# plt.ylabel('tatti')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " sns.factorplot('movement', data=dropData, kind='count') #testing data by visualising\n",
    " #this data graph shows that people spend much more meaning money is debited more than credited."
   ]
  },
  {
   "source": [
    "Average Transaction Amount"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = dropData[dropData.movement == 'debit'] #getting values of all columns only where movement is debit \n",
    "AvgtransAmount = transactions['amount']\n",
    "#AvgtransAmount.describe()\n",
    "AvgtransAmount.mean()\n",
    "#AvgtransAmount.describe()"
   ]
  },
  {
   "source": [
    "Average number of transactions per month"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transactions['extraction'] = pd.to_datetime(transactions.extraction) #converting time format in the dataframe to pandas datatime format. Changing only the extraction column\n",
    "extractionByMonth = transactions.extraction.dt.month #extracting the month data only\n",
    "extractionByMonth.head()\n",
    "\n",
    "augustValues = []\n",
    "septValues = []\n",
    "octValues = []\n",
    "\n",
    "for month in extractionByMonth:\n",
    "    \"\"\"Seperating months of August for further processing\"\"\"\n",
    "    if month == 8:\n",
    "        augustValues.append(True)\n",
    "    else:\n",
    "        augustValues.append(False)\n",
    "    \n",
    "for month in extractionByMonth:\n",
    "    \"\"\"Seperating months of August for further processing\"\"\"\n",
    "    if month == 9:\n",
    "        septValues.append(True)\n",
    "    else:\n",
    "        septValues.append(False)\n",
    "    \n",
    "for month in extractionByMonth:\n",
    "    \"\"\"Seperating months of August for further processing\"\"\"\n",
    "    if month == 10:\n",
    "        octValues.append(True)\n",
    "    else:\n",
    "        octValues.append(False)\n",
    "\n",
    "augustData = transactions.loc[augustValues] #displays the dataframe with all the other column values that fall in the month of august\n",
    "septData = transactions.loc[septValues] #displays the dataframe with all the other column values that fall in the month of september\n",
    "octData = transactions.loc[octValues] #displays the dataframe with all the other column values that fall in the month of october\n",
    "\n",
    "\n",
    "repeatCust_idAug = pd.DataFrame(augustData, columns=['customer_id']) #finding the repeating items in the column and adding the number of times each customer id is repeated \n",
    "repCustTotalAug = repeatCust_idAug.pivot_table(index=['customer_id'], aggfunc='size') #number of times each customer_id has been repeated\n",
    "\n",
    "repeatCust_idSept = pd.DataFrame(septData, columns=['customer_id']) #finding the repeating items in the column and adding the number of times each customer id is repeated \n",
    "repCustTotalSept = repeatCust_idSept.pivot_table(index=['customer_id'], aggfunc='size') #number of times each customer_id has been repeated\n",
    "\n",
    "repeatCust_idOct = pd.DataFrame(octData, columns=['customer_id']) #finding the repeating items in the column and adding the number of times each customer id is repeated \n",
    "repCustTotalOct = repeatCust_idOct.pivot_table(index=['customer_id'], aggfunc='size') #number of times each customer_id has been repeated\n",
    "\n",
    "averageTranPerMonth = [repCustTotalAug.mean(), repCustTotalSept.mean(), repCustTotalOct.mean()] \n",
    "averageTranPerMonthSeries = pd.Series(averageTranPerMonth)\n",
    "\n",
    "sns.factorplot(extractionByMonth, data=dropData, kind='count')\n",
    "#print(int(averageTranPerMonthSeries.mean()))\n",
    "\n"
   ]
  },
  {
   "source": [
    "Segmenting the data\n",
    "\n",
    "We will take the whole column(extraction) and then extarct the first week of August and then display the transaction volume in the week. This will include credit and debit \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testWeek = transactions.extraction.dt.dayofweek\n",
    "#testWeek.head()\n",
    "#augustData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extraction = pd.to_datetime( dropData['extraction']) #converted all dates\n",
    "#df_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractionByWeek = df_extraction.dt.isocalendar().week #filtering by week of the year\n",
    "extractionByWeekOne = extractionByWeek[extractionByWeek == 31]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extractionByWeekOne\n",
    "#extractionByWeekOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "datetime.date(2018, 8, 1).isocalendar()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}